{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a337539",
   "metadata": {},
   "source": [
    "# PR√ÅCTICA DE TERREMOTOS UTILIZANDO CASSANDRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422c1765",
   "metadata": {},
   "source": [
    "En esta pr√°ctica se usar√° la base de datos NoSQL de Cassandra, para el caso de uso de modelaci√≥n de una serie de consultas.\n",
    "\n",
    "En el caso de los datos s√≠smicos, el volumen, la variedad y, especialmente, la\n",
    "velocidad de generaci√≥n de la informaci√≥n (nuevos registros de sensores, actualizaciones de\n",
    "magnitudes, alertas de tsunami, datos geoespaciales y de profundidad) hacen que un enfoque\n",
    "relacional resulte poco eficiente para este caso de uso.\n",
    "\n",
    "A continuaci√≥n se observar√° el criterio de elecci√≥n de Cassandra como base de datos NoSQL para modelar las consultas, as√≠ como el modelo de datos de las distintas tablas, inserci√≥n y actualizaci√≥n de datos, y la creaci√≥n y ejecuci√≥n de las consultas SQL propuestas en la actividad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40907b55",
   "metadata": {},
   "source": [
    "## 1. Ventajas y desventajas de Cassandra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c399576a",
   "metadata": {},
   "source": [
    "Antes de empezar con ventajas y desventajas, se debe de analizar el teorema CAP, para saber de forma general si Cassandra es de utilidad en nuestro caso de uso de Terremotos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfe1d12",
   "metadata": {},
   "source": [
    "### ===================\n",
    "### Teorema CAP en Cassandra\n",
    "### ==================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf521c32",
   "metadata": {},
   "source": [
    "* ¬øQue cumple simpre?:\n",
    "    * Tolerancia a particiones (P): En un entorno real, Cassandra usa varios nodos a modo de backup siguiendo una topolog√≠a de anillo. Por tanto, el sistema sigue funcionando aunque haya fallos o cortes de red entre nodos.\n",
    "    * Disponibilidad (A): Siempre responde a las peticiones (lecturas/escrituras), aunque algunos datos puedan no estar totalmente sincronizados.\n",
    "\n",
    "* ¬øQue no cumple siempre?:\n",
    "    * Consistencia (C): Se sacrifica parcialmente, ya que los datos pueden tardar un poco en propagarse entre nodos. Esto se conoce como consistencia eventual.\n",
    "\n",
    "* ¬øRealmente sirve Cassandra en este caso de uso?\n",
    "\n",
    "    * Seg√∫n el teorema CAP, Cassandra es adecuada para este caso porque en un sistema global y distribuido de datos s√≠smicos es m√°s importante no perder datos y mantener el servicio disponible que tener consistencia instant√°nea en todas las r√©plicas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9448ed16",
   "metadata": {},
   "source": [
    "### ======\n",
    "### Ventajas\n",
    "### ======"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eaccc4",
   "metadata": {},
   "source": [
    "* Alta escalabilidad horizontal: permite a√±adir nodos f√°cilmente sin afectar la disponibilidad ni el rendimiento.\n",
    "\n",
    "* Alt√≠sima velocidad de escritura: ideal para registrar datos de sensores y eventos s√≠smicos en tiempo real.\n",
    "\n",
    "* Disponibilidad continua: sin un √∫nico punto de fallo gracias a su arquitectura distribuida y replicaci√≥n entre nodos.\n",
    "\n",
    "* Modelo flexible de datos: no se requiere esquema r√≠gido, como pasa en SQL. Cassandra puede adaptarse f√°cilmente a nuevos tipos de datos, por ejemplo a nuevos par√°metros geol√≥gicos que previamente no estaban definidos.\n",
    "\n",
    "* Replicaci√≥n geogr√°fica: los datos se podr√≠an replicarse entre regiones o continentes, √∫til para observatorios s√≠smicos internacionales.\n",
    "\n",
    "* Lecturas r√°pidas por clave: muy eficiente para consultas que acceden por identificadores concretos (ID de evento, zona, etc.).\n",
    "\n",
    "* Tolerancia a fallos: sigue funcionando incluso si algunos nodos o centros de datos quedan fuera de servicio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d8de5a",
   "metadata": {},
   "source": [
    "### =========\n",
    "### Desventajas\n",
    "### ========="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fbb440",
   "metadata": {},
   "source": [
    "* No soporta transacciones complejas ni joins: En el momento que la consulta sea un poco m√°s compleja de lo habitual y requiriese un acceso multitabla.\n",
    "\n",
    "* Curva de aprendizaje: Requiere entender muy bien el modelo de datos y tener muy bien especificadas las consultas a resolver. Esto genera mucho debate a la hora de construir las tablas que ejecuten de manera √≥ptima la query, si se quiere evitar el allow filtering.\n",
    "\n",
    "* Consistencia eventual: Como se ha visto antes, puede haber peque√±os retrasos en la sincronizaci√≥n entre r√©plicas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c288ea7",
   "metadata": {},
   "source": [
    "## 2. CREACI√ìN DE LAS TABLAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f55b337",
   "metadata": {},
   "source": [
    "### ==========================\n",
    "### Celda 1: Inicializaci√≥n y Conexi√≥n\n",
    "### =========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "030626c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intentando conectar a Cassandra en ['127.0.0.1']:9042...\n",
      "‚úÖ Conexi√≥n exitosa al cluster en el intento 1.\n",
      "üîë KEYSAPCE 'seismic_data' activo.\n",
      "Versi√≥n de Cassandra: 5.0.5\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "from cassandra import OperationTimedOut\n",
    "\n",
    "# --- Configuraci√≥n ---\n",
    "CASSANDRA_HOSTS = ['127.0.0.1'] \n",
    "PORT = 9042\n",
    "KEYSPACE = 'seismic_data'\n",
    "\n",
    "# 1. Conexi√≥n al Cluster con reintentos para dar tiempo al contenedor a inicializarse\n",
    "cluster = None\n",
    "session = None\n",
    "RETRY_ATTEMPTS = 15\n",
    "RETRY_DELAY_SEC = 10 \n",
    "\n",
    "print(f\"Intentando conectar a Cassandra en {CASSANDRA_HOSTS}:{PORT}...\")\n",
    "\n",
    "for i in range(RETRY_ATTEMPTS):\n",
    "    try:\n",
    "        # Me conecto desde el host de WSL\n",
    "        cluster = Cluster(CASSANDRA_HOSTS, port=PORT) \n",
    "        session = cluster.connect()\n",
    "        print(f\"‚úÖ Conexi√≥n exitosa al cluster en el intento {i+1}.\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error de conexi√≥n (Intento {i+1}/{RETRY_ATTEMPTS}): {e}\")\n",
    "        if i < RETRY_ATTEMPTS - 1:\n",
    "            print(f\"Esperando {RETRY_DELAY_SEC} segundos...\")\n",
    "            time.sleep(RETRY_DELAY_SEC)\n",
    "        else:\n",
    "            print(\"üö® Fallo al conectar despu√©s de varios intentos.\")\n",
    "            raise ConnectionError(\"No se pudo conectar al cluster de Cassandra.\")\n",
    "\n",
    "\n",
    "# 2. Establecer Keyspace y Verificar Versi√≥n\n",
    "if session:\n",
    "    # Crear Keyspace (se debe hacer en la sesi√≥n inicial)\n",
    "    session.execute(f\"\"\"\n",
    "        CREATE KEYSPACE IF NOT EXISTS {KEYSPACE}\n",
    "        WITH replication = {{'class': 'SimpleStrategy', 'replication_factor': '1'}}\n",
    "    \"\"\")\n",
    "    session.set_keyspace(KEYSPACE)\n",
    "    print(f\"üîë KEYSAPCE '{KEYSPACE}' activo.\")\n",
    "    \n",
    "    # Mostrar versi√≥n\n",
    "    rows = session.execute(\"SELECT release_version FROM system.local;\").one()\n",
    "    print(f\"Versi√≥n de Cassandra: {rows.release_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7cca3a",
   "metadata": {},
   "source": [
    "### =========================\n",
    "### Creaci√≥n de las 4 Tablas Optimizadas\n",
    "### ========================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d33b8f",
   "metadata": {},
   "source": [
    "A continuaci√≥n se procede a la creaci√≥n de las 4 tablas, una para cada una de las queies propuestas en la actividad\n",
    "\n",
    "Las consultas a realizar son las siguientes:\n",
    " - 5.a.i: Filtra terremotos por el a√±o del evento mayor de 2015.\n",
    " - 5.a.ii: Filtra terremotos en el pa√≠s donde ocurri√≥ y que empiece por: ‚ÄúJapa...‚Äù para el caso de \"Japan\".\n",
    " - 5.b.i: Consulta por un pa√≠s concreto donde se han producido terremotos, mostrando todos los terremotos con magnitud superior a 7.0.\n",
    " - 5.b.ii: Consulta por un pa√≠s concreto donde se han producido terremotos, incluyendo s√≥lo los que presenten riesgo potencial de tsunami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab74300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Creando las 4 Tablas optimizadas para las consultas...\n",
      "‚úÖ Las 4 Tablas han sido creadas/verificadas con el esquema de optimizaci√≥n revisado (SIN UDTs).\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCreando las 4 Tablas optimizadas para las consultas...\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# TABLA 1: earthquakes_by_year_range (Optimiza: 5.a.i -> eq_id y A√±o > 2015)\n",
    "# Estrategia: Particionar por grupo de a√±os (old vs. new) para escalar.\n",
    "# L√≥gica PK: year_pk = 'False' (si < 2015) o 'True' (si >= 2015).\n",
    "# Clustering Key 1: Permite el filtro de rango (event_year > 2015).\n",
    "# ----------------------------------------------------------------------\n",
    "session.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS earthquakes_by_year_range (\n",
    "        year_pk boolean,      \n",
    "        event_year int,\n",
    "        eq_id text,\n",
    "        \n",
    "        event_time timestamp, \n",
    "        intensity_mmi decimal, \n",
    "        country text, \n",
    "        duration_sec int,\n",
    "        \n",
    "        PRIMARY KEY (year_pk, event_year, eq_id)\n",
    "    ) WITH CLUSTERING ORDER BY (event_year ASC, eq_id ASC);\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# TABLA 2: earthquakes_by_country_initial (Optimiza: 5.a.ii -> eq_id y Pa√≠s 'Japa...')\n",
    "# Estrategia: Particionar por la inicial del pa√≠s (A-Z) para acortar las particiones.\n",
    "# L√≥gica PK: country_initial_pk = Primera letra del Pa√≠s (ej: 'J' para Japan).\n",
    "# Clustering Key 1: Permite el filtro de rango (>= 'Japa' AND < 'Japb').\n",
    "# ----------------------------------------------------------------------\n",
    "session.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS earthquakes_by_country_starting_with_prefix (\n",
    "        country_initial_pk text,\n",
    "        country text,\n",
    "        eq_id text,\n",
    "        \n",
    "        event_time timestamp, \n",
    "        intensity_mmi decimal,\n",
    "        duration_sec int,\n",
    "        \n",
    "        PRIMARY KEY (country_initial_pk, country, eq_id)\n",
    "    ) WITH CLUSTERING ORDER BY (country ASC, eq_id ASC);\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# TABLA 3: earthquakes_by_country_and_magnitude (Optimiza: 5.b.i -> Pa√≠s y Magnitud > 7.0)\n",
    "# Estrategia: La PK es el Pa√≠s, ya que la consulta es \"por un pa√≠s concreto\".\n",
    "# Clustering Key 1: Permite el filtro de rango (mw > 7.0).\n",
    "# Clustering Key 2: Ordenar por evento m√°s reciente.\n",
    "# ----------------------------------------------------------------------\n",
    "session.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS earthquakes_by_country_and_magnitude (\n",
    "        country text,\n",
    "        mw decimal,\n",
    "        event_time timestamp,\n",
    "        \n",
    "        eq_id text,\n",
    "        intensity_mmi decimal,\n",
    "        duration_sec int,\n",
    "        \n",
    "        PRIMARY KEY (country, mw, event_time)\n",
    "    ) WITH CLUSTERING ORDER BY (mw DESC, event_time DESC); \n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# TABLA 4: tsunami_potential_by_country (Optimiza: 5.b.ii -> Pa√≠s y riesgo potencial=TRUE)\n",
    "# Estrategia: Partici√≥n Compuesta (Pa√≠s, Tsunami Boolean) para acceder directamente a TRUE/FALSE.\n",
    "# Clustering Key 1: Ordenar por evento m√°s reciente.\n",
    "# ----------------------------------------------------------------------\n",
    "session.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS tsunami_potential_by_country (\n",
    "        country text,\n",
    "        tsunami_potential boolean,\n",
    "        event_time timestamp,\n",
    "        \n",
    "        -- Datos Desnormalizados\n",
    "        eq_id text,\n",
    "        mw decimal,\n",
    "        intensity_mmi decimal,\n",
    "        \n",
    "        PRIMARY KEY ((country, tsunami_potential), event_time) -- PK Compuesta\n",
    "    ) WITH CLUSTERING ORDER BY (event_time DESC);\n",
    "\"\"\")\n",
    "\n",
    "print(\"Status=OK --> Las 4 Tablas han sido creadas/verificadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5ee35f",
   "metadata": {},
   "source": [
    "## 3. INSERCI√ìN DE DATOS EN CASSANDRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdafc4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chequia', 'Barbados', 'Antarctica', 'Zambia', 'Canada', 'Andorra', 'Suriname', 'Cameroon', 'China', 'Romania']\n"
     ]
    }
   ],
   "source": [
    "import pycountry\n",
    "import random\n",
    "\n",
    "def random_country(country_set):\n",
    "    countries = [c.name for c in pycountry.countries if c.name != \"Czechia\" and  c.name not in country_set]\n",
    "    return random.choice(countries)\n",
    "\n",
    "\n",
    "country_set = set(['Antarctica', 'Andorra', 'Chequia', 'Cameroon', 'Canada'])\n",
    "\n",
    "while len(country_set) < 9:\n",
    "    country_set.add(random_country(country_set=country_set))\n",
    "\n",
    "top_9_countries = list(country_set)\n",
    "print(top_9_countries)\n",
    "\n",
    "def get_country():\n",
    "    return random.choice(top_9_countries) if random.random() < 0.7 else 'China'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a140366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_pk(year):\n",
    "    return True if year >= 2015 else False\n",
    "\n",
    "def country_initial(country):\n",
    "    return country[0].upper() if isinstance(country, str) and country else \"X\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8588330e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 100 registros insertados en las 4 tablas adaptadas.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "df = pd.read_csv(\"./data/earthquake_data_tsunami.csv\")\n",
    "df_sample = df.sample(n=100, random_state=42).reset_index(drop=True)  # 100 filas aleatorias del dataset\n",
    "\n",
    "# === Insertar registros adaptados a las 4 tablas ===\n",
    "for idx, row in df_sample.iterrows():\n",
    "    eq_id = f\"eq_{idx+1:03d}\"\n",
    "    event_year = int(row['Year']) if random.random() <= 0.5 else random.choice([2012, 2013, 2014])\n",
    "    event_time = datetime(event_year, int(row['Month']), 1)\n",
    "    intensity_mmi = float(row['mmi'])\n",
    "    country = get_country()\n",
    "    duration_sec = random.randint(10, 600)\n",
    "    mw = float(row['magnitude'])\n",
    "    tsunami = bool(row['tsunami'])\n",
    "\n",
    "    # --- Tabla 1: earthquakes_by_year_range ---\n",
    "    session.execute(\"\"\"\n",
    "        INSERT INTO earthquakes_by_year_range (year_pk, event_year, eq_id, event_time, intensity_mmi, country, duration_sec)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\", (year_pk(event_year), event_year, eq_id, event_time, intensity_mmi, country, duration_sec))\n",
    "\n",
    "    # --- Tabla 2: earthquakes_by_country_starting_with_prefix ---\n",
    "    country_initial_pk = country[0]\n",
    "    session.execute(\"\"\"\n",
    "        INSERT INTO earthquakes_by_country_starting_with_prefix (country_initial_pk, country, eq_id, event_time, intensity_mmi, duration_sec)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\", (country_initial(country), country, eq_id, event_time, intensity_mmi, duration_sec))\n",
    "\n",
    "    # --- Tabla 3: earthquakes_by_country_and_magnitude ---\n",
    "    session.execute(\"\"\"\n",
    "        INSERT INTO earthquakes_by_country_and_magnitude (country, mw, event_time, eq_id, intensity_mmi, duration_sec)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\", (country, mw, event_time, eq_id, intensity_mmi, duration_sec))\n",
    "\n",
    "    # --- Tabla 4: tsunami_potential_by_country ---\n",
    "    session.execute(\"\"\"\n",
    "        INSERT INTO tsunami_potential_by_country (country, tsunami_potential, event_time, eq_id, mw, intensity_mmi)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\", (country, tsunami, event_time, eq_id, mw, intensity_mmi))\n",
    "\n",
    "print(\"Status=OK --> 100 registros insertados en las 4 tablas adaptadas.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d187ede1",
   "metadata": {},
   "source": [
    "## 4. UPDATE EN CASSANDRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e128dd20",
   "metadata": {},
   "source": [
    "Elegimos la tabla *earthquakes_by_country_and_magnitude*, en la que vamos a actualizar un registro.\n",
    "\n",
    "Tal y como nos pone el enunciado, tenemos que actualizar los registros de un pa√≠s concreto, cambiando el nombre del pa√≠s a letras may√∫sculas. \n",
    "\n",
    " - Ej: China ‚Üí CHINA.\n",
    "\n",
    "Usaremos \"China\" como pa√≠s a actualizar, dado que en `get_country()` hemos puesto por defecto que retorne \"China\" un 30% de las veces, para estar bastante seguros que hay datos para actualizar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48e2b878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> Registro encontrado: Row(country='China', mw=Decimal('7.5'), event_time=datetime.datetime(2007, 1, 1, 0, 0), eq_id='eq_087', intensity_mmi=Decimal('5.0'), duration_sec=215)\n",
      " -> Registro insertado con country='CHINA', eq_id=eq_087\n",
      " -> Registro eliminado para country='China', eq_id=eq_087\n",
      "\n",
      " -> Registros verificados con country='CHINA':\n",
      "Row(country='CHINA', eq_id='eq_023', mw=Decimal('7.7'), intensity_mmi=Decimal('4.0'), event_time=datetime.datetime(2013, 2, 1, 0, 0))\n",
      "Row(country='CHINA', eq_id='eq_087', mw=Decimal('7.5'), intensity_mmi=Decimal('5.0'), event_time=datetime.datetime(2007, 1, 1, 0, 0))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "country_used_to_delete = 'China'\n",
    "\n",
    "\n",
    "row = session.execute(\"\"\"\n",
    "    SELECT country, mw, event_time, eq_id, intensity_mmi, duration_sec\n",
    "    FROM earthquakes_by_country_and_magnitude\n",
    "    WHERE country = %s\n",
    "\"\"\", (country_used_to_delete,)).one()\n",
    "\n",
    "if not row:\n",
    "    print(f\"No se encontr√≥ ning√∫n registro con country='{country_used_to_delete}'\")\n",
    "else:\n",
    "    print(\" -> Registro encontrado:\", row)\n",
    "\n",
    "    mw = row.mw\n",
    "    event_time = row.event_time\n",
    "    eq_id = row.eq_id\n",
    "    intensity_mmi = row.intensity_mmi\n",
    "    duration_sec = row.duration_sec\n",
    "\n",
    "    # Insertamos el registro existente con el nuevo campo 'CHINA'\n",
    "    insert_cql = \"\"\"\n",
    "        INSERT INTO earthquakes_by_country_and_magnitude \n",
    "        (country, mw, event_time, eq_id, intensity_mmi, duration_sec)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    session.execute(insert_cql, ('CHINA', mw, event_time, eq_id, intensity_mmi, duration_sec))\n",
    "    print(f\" -> Registro insertado con country='CHINA', eq_id={eq_id}\")\n",
    "\n",
    "    # Borramos el registro antiguo, ya que UPDATE no borra\n",
    "    delete_cql = \"\"\"\n",
    "        DELETE FROM earthquakes_by_country_and_magnitude\n",
    "        WHERE country=%s AND mw=%s AND event_time=%s\n",
    "    \"\"\"\n",
    "    session.execute(delete_cql, (country_used_to_delete, mw, event_time))\n",
    "    print(f\" -> Registro eliminado para country='{country_used_to_delete}', eq_id={eq_id}\")\n",
    "\n",
    "    # Verificamos\n",
    "    result = session.execute(\"\"\"\n",
    "        SELECT country, eq_id, mw, intensity_mmi, event_time\n",
    "        FROM earthquakes_by_country_and_magnitude\n",
    "        WHERE country = %s\n",
    "    \"\"\", ('CHINA',))\n",
    "\n",
    "    print(\"\\n -> Registros verificados con country='CHINA':\")\n",
    "    for r in result:\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bf24f9",
   "metadata": {},
   "source": [
    "## 5. CONSULTAS CQL Y PRUEBAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476174ba",
   "metadata": {},
   "source": [
    "### ===================\n",
    "### Definici√≥n de las Queries\n",
    "### ==================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54583e27",
   "metadata": {},
   "source": [
    "Query 5.a.i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40ad9943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_earthquake_by_year_range(session, year):  \n",
    "    query = \"\"\"\n",
    "    SELECT * FROM earthquakes_by_year_range \n",
    "    WHERE year_pk = ?  \n",
    "      AND event_year > ?\n",
    "    \"\"\"\n",
    "    prepared = session.prepare(query)\n",
    "\n",
    "    start_time = time.time()\n",
    "    rows = session.execute(prepared, (year_pk(year), year))\n",
    "    end_time = time.time()\n",
    "\n",
    "    time_ms = (end_time - start_time) * 1000\n",
    "\n",
    "    return rows, time_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b205e7",
   "metadata": {},
   "source": [
    "Query 5.a.ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d8443ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_prefix(prefix):\n",
    "    if not prefix:\n",
    "        return None\n",
    "    last_char = prefix[-1]\n",
    "    next_char = chr(ord(last_char) + 1)\n",
    "    return prefix[:-1] + next_char\n",
    "\n",
    "def query_earthquake_by_country_prefix(session, country_prefix):\n",
    "    c_i = country_initial(country_prefix)\n",
    "    upper_bound = get_next_prefix(country_prefix)\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT * FROM earthquakes_by_country_starting_with_prefix \n",
    "    WHERE country_initial_pk = ? \n",
    "      AND country >= ? \n",
    "      AND country < ?\n",
    "    \"\"\"\n",
    "    prepared = session.prepare(query)\n",
    "\n",
    "    start_time = time.time()\n",
    "    rows = session.execute(prepared, (c_i, country_prefix, upper_bound))\n",
    "    end_time = time.time()\n",
    "\n",
    "    time_ms = (end_time - start_time) * 1000\n",
    "\n",
    "    return rows, time_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a25575",
   "metadata": {},
   "source": [
    "Query 5.b.i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7e6a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "def query_earthquakes_by_magnitude(session, country, min_magnitude):\n",
    "    query = \"\"\"\n",
    "    SELECT * FROM earthquakes_by_country_and_magnitude \n",
    "    WHERE country = ? \n",
    "      AND mw > ?\n",
    "    \"\"\"\n",
    "    prepared = session.prepare(query)\n",
    "\n",
    "    start_time = time.time()\n",
    "    rows = session.execute(prepared, (country, Decimal(str(min_magnitude))))\n",
    "    end_time = time.time()\n",
    "\n",
    "    time_ms = (end_time - start_time) * 1000\n",
    "\n",
    "    return rows, time_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a7d2de",
   "metadata": {},
   "source": [
    "Query 5.b.ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71a9f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_tsunami_potential_by_country(session, country_name):\n",
    "    \n",
    "    query = \"\"\"\n",
    "    SELECT * FROM tsunami_potential_by_country \n",
    "    WHERE country = ? \n",
    "      AND tsunami_potential = ?\n",
    "    \"\"\"\n",
    "    prepared = session.prepare(query)\n",
    "\n",
    "    start_time = time.time()\n",
    "    rows = session.execute(prepared, (country_name, True))\n",
    "    end_time = time.time()\n",
    "\n",
    "    time_ms = (end_time - start_time) * 1000\n",
    "\n",
    "    return rows, time_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e5adfa",
   "metadata": {},
   "source": [
    "### ===================\n",
    "### Testeo de las Queries\n",
    "### ==================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85820cd8",
   "metadata": {},
   "source": [
    "#### 5.a.i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68e71229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year_pk  event_year   eq_id   country  duration_sec event_time  \\\n",
      "0     True        2018  eq_055  Suriname           443 2018-08-01   \n",
      "1     True        2018  eq_080  Cameroon           300 2018-02-01   \n",
      "2     True        2019  eq_033   Romania           248 2019-01-01   \n",
      "3     True        2019  eq_091  Barbados           481 2019-08-01   \n",
      "4     True        2020  eq_084  Barbados           467 2020-06-01   \n",
      "\n",
      "  intensity_mmi  \n",
      "0           6.0  \n",
      "1           7.0  \n",
      "2           3.0  \n",
      "3           6.0  \n",
      "4           7.0  \n",
      "\n",
      "-> Tiempo de ejecuci√≥n: 9.198427200317383 ms; Registros totales obtenidos: 13\n",
      "\n",
      "-> Frecuencia de registros >= 2015: 13\n"
     ]
    }
   ],
   "source": [
    "year = 2017\n",
    "rows, elapsed_time = query_earthquake_by_year_range(session, year)\n",
    "\n",
    "df = pd.DataFrame(list(rows))\n",
    "\n",
    "if df.shape[0] > 0:\n",
    "    frec_yearPk = df['year_pk'].value_counts().values\n",
    "    print(df.head())\n",
    "    print(f\"\\n-> Tiempo de ejecuci√≥n: {elapsed_time} ms; Registros totales obtenidos: {df.shape[0]}\")\n",
    "    print(f'\\n-> Frecuencia de registros >= 2015: {df[df['year_pk'] == True].shape[0]}')\n",
    "\n",
    "else:\n",
    "    if year < 2015:\n",
    "        print(f\"No hay ning√∫n registro desde {year} hasta 2015\")\n",
    "    else:\n",
    "        print(f\"No hay ning√∫n registro >= {year}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7c0b9e",
   "metadata": {},
   "source": [
    "Se simula la query filtrando por un a√±o mayor o igual a 2015. Cabe destacar que la l√≥gica ha sido generalizada para soportar tambi√©n a√±os inferiores a 2015, buscando desde ese a√±o hasta 2015 (Ej: 2013 hasta 2015). Se puede probar con otro a√±o para validar varios casos y la tabla en cuesti√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce6d33e",
   "metadata": {},
   "source": [
    "Si el a√±o es igual o superior a 2015 se observar√° un otuput con este formato:\n",
    "\n",
    "    -> Tiempo de ejecuci√≥n: 4.205226898193359 ms; Registros totales obtenidos: N\n",
    "\n",
    "    -> Frecuencia de registros >= 2015: N\n",
    "\n",
    "El n√∫mero total de registros siempre ser√° igual a la frecuencia de los registros mayores a 2015 --> N registros.\n",
    "\n",
    "Si el a√±o es inferior a 2015, se observar√° un output de este estilo:\n",
    "    \n",
    "    -> Tiempo de ejecuci√≥n: 4.205226898193359 ms; Registros totales obtenidos: K\n",
    "\n",
    "    -> Frecuencia de registros >= 2015: 0\n",
    "\n",
    "La frecuencia de los registros mayores a 2015 ser√° siempre 0, confirm√°ndonos que las particiones act√∫an de manera correcta, mandando los registros con a√±os >= 2015 a una partici√≥n y los inferiores a la otra partici√≥n, balanceando la carga."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35166063",
   "metadata": {},
   "source": [
    "#### 5.a.ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2813fc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  country_initial_pk   country   eq_id  duration_sec event_time intensity_mmi\n",
      "0                  C  Cameroon  eq_001           589 2012-08-01           6.0\n",
      "1                  C  Cameroon  eq_006            39 2013-07-01           4.0\n",
      "2                  C  Cameroon  eq_012           163 2002-07-01           7.0\n",
      "3                  C  Cameroon  eq_013           320 2016-11-01           9.0\n",
      "4                  C  Cameroon  eq_021           246 2014-05-01           4.0\n",
      "\n",
      "-> Tiempo de ejecuci√≥n: 6.857156753540039 ms; Filas obtenidas: 40\n",
      "\n",
      "-> Frecuencias de cada pa√≠s:\n",
      "country\n",
      "Cameroon    15\n",
      "China       10\n",
      "Chequia      8\n",
      "Canada       7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "rows, elapsed_time = query_earthquake_by_country_prefix(session, 'C')\n",
    "\n",
    "df = pd.DataFrame(list(rows))\n",
    "frecuencia_paises = df['country'].value_counts()\n",
    "print(df.head())\n",
    "print(f\"\\n-> Tiempo de ejecuci√≥n: {elapsed_time} ms; Filas obtenidas: {df.shape[0]}\")\n",
    "print('\\n-> Frecuencias de cada pa√≠s:')\n",
    "print(frecuencia_paises)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e04a39",
   "metadata": {},
   "source": [
    "Se puede observar que en cada partici√≥n se guardan las iniciales del pa√≠s:\n",
    "\n",
    "    -> Prefix = 'An' --> 'Andorra', 'Antartica'\n",
    "    -> Prefix = 'Ch' --> 'Chequia', 'Chile', 'China' \n",
    "    -> Prefix = 'Chi' --> 'Chile', 'China' \n",
    "\n",
    "Se puede ver con esto, que las particiones por iniciales funcionan bien para balancear la carga y que adem√°s sea capaz de buscar paises por prefijos en una misma partici√≥n.\n",
    "\n",
    "Tambi√©n se puede observar la actuaci√≥n de la Clustering Key en el \"df.head\", dado que sacar√° lso registros ordenados alfab√©ticamente por Country."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22713a70",
   "metadata": {},
   "source": [
    "#### 5.b.i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fdade2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  country   mw event_time  duration_sec   eq_id intensity_mmi\n",
      "0   China  7.7 2013-02-01            30  eq_023           4.0\n",
      "1   China  7.5 2007-01-01           215  eq_087           5.0\n",
      "\n",
      "-> Tiempo de ejecuci√≥n: 5.151271820068359 ms; Filas obtenidas: 2\n",
      "\n",
      "-> Frecuencia escalas superiores a 7.0:\n",
      "country  mw   event_time  duration_sec  eq_id   intensity_mmi\n",
      "China    7.5  2007-01-01  215           eq_087  5.0              1\n",
      "         7.7  2013-02-01  30            eq_023  4.0              1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mw = 7.1\n",
    "rows, elapsed_time = query_earthquakes_by_magnitude(session, 'China', mw)\n",
    "\n",
    "df = pd.DataFrame(list(rows))\n",
    "\n",
    "if df.shape[0] > 0:\n",
    "    frecu_escala = df[df['mw'] >= 7.0].value_counts()\n",
    "    print(df.head())\n",
    "    print(f\"\\n-> Tiempo de ejecuci√≥n: {elapsed_time} ms; Filas obtenidas: {df.shape[0]}\")\n",
    "    print(f'\\n-> Frecuencia escalas superiores a 7.0:')\n",
    "    print(frecu_escala)\n",
    "else:\n",
    "    print(f\"No hay escala disponible a partir de {mw}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b052498",
   "metadata": {},
   "source": [
    "En este filtro se puede observar que algunos de los pa√≠ses no contienen magnitudes superiores a 7.0\n",
    "\n",
    "De acuerdo al dataset, la mayor√≠a de las magnitudes no son superiores a 7, y al recolectar los datos de ese dataset, cuenta con esta implicaci√≥n a tener en cuenta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e70dd93",
   "metadata": {},
   "source": [
    "#### 5.b.ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4870bd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    country  tsunami_potential event_time   eq_id intensity_mmi   mw\n",
      "0  Cameroon               True 2021-02-01  eq_049           8.0  7.1\n",
      "1  Cameroon               True 2018-02-01  eq_080           7.0  7.2\n",
      "2  Cameroon               True 2016-11-01  eq_013           9.0  7.8\n",
      "3  Cameroon               True 2013-10-01  eq_051           6.0  7.3\n",
      "4  Cameroon               True 2013-09-01  eq_094           9.0  6.9\n",
      "\n",
      "-> Tiempo de ejecuci√≥n: 4.462003707885742 ms; Filas obtenidas: 6\n",
      "\n",
      "-> Frecuencia de riesgos potenciales de sunami en Cameroon: 6\n"
     ]
    }
   ],
   "source": [
    "country = 'Cameroon'\n",
    "rows, elapsed_time = query_tsunami_potential_by_country(session, country)\n",
    "\n",
    "df = pd.DataFrame(list(rows))\n",
    "\n",
    "if df.shape[0] > 0:\n",
    "    print(df.head())\n",
    "    print(f\"\\n-> Tiempo de ejecuci√≥n: {elapsed_time} ms; Filas obtenidas: {df.shape[0]}\")\n",
    "    print(f'\\n-> Frecuencia de riesgos potenciales de sunami en {country}: {df[df['tsunami_potential'] == True].shape[0]}')\n",
    "else:\n",
    "    print(f\"{country} no tiene riesgo potencial de tsunami\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c869843b",
   "metadata": {},
   "source": [
    "Recordemos que en esta consulta, la partition key est√° compuesta con el pa√≠s y el riesgo de tsunami, ya que as√≠ podemos buscar en la misma partici√≥n de una manera muy r√°pida, el pa√≠s que tenga riesgo de tsunami, y a parte balanceando mucho m√°s la carga dado que los registro de ese mismo pa√≠s que no tienen rsiego de sunami van a ir a otra partici√≥n.\n",
    "\n",
    "Como se puede evaluar en la frecuencia de riesgos de tsunami en el filtro, coincide con el total de registros obtenidos, lo que nos indica que la consulta es consistente, ya que solo queremos sacar los riesgos potenciales de dicho pa√≠s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98615d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dd67dc",
   "metadata": {},
   "source": [
    "Una vez se acabe todo el flujo de sesi√≥n, desconecta el cluster para no tener muchas sesiones abiertas.\n",
    "\n",
    "Si se quiere volver a re ejecutar otra vez alguna celda concreta, tienes que volver a ejecutar la celda 1 de Inicializaci√≥n y Conexi√≥n."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cassandra-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
